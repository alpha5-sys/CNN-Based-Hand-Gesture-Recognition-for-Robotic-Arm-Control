{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASL Gesture Recognition with 1D CNN\n",
    "#This notebook demonstrates the process of training a 1D CNN for recognizing American Sign Language gestures using sensor data.\n",
    "\n",
    "## Step 1: Import Libraries\n",
    "#```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization, Dropout, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Define Data Directory\n",
    "# Specify the path to your dataset directory.\n",
    "# ```python\n",
    "data_dir = r'C:\\Users\\Niklesh\\Documents\\Capstone Project\\Project code\\my_dataset_robotic_arm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Feature Extraction Function\n",
    "# Define a function to extract features from CSV files.\n",
    "# ```python\n",
    "def extract_features_from_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    features = df.drop(columns=['timestamp', 'user_id']).values\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5: Load Dataset\n",
    "# Define a function to load data from the specified directory.\n",
    "# ```python\n",
    "def load_data_from_directory(data_dir):\n",
    "    X, y = [], []\n",
    "    for user in os.listdir(data_dir):\n",
    "        user_path = os.path.join(data_dir, user)\n",
    "        if os.path.isdir(user_path):\n",
    "            for file in os.listdir(user_path):\n",
    "                if file.endswith('.csv'):\n",
    "                    file_path = os.path.join(user_path, file)\n",
    "                    features = extract_features_from_csv(file_path)\n",
    "                    gesture_label = os.path.splitext(file)[0]\n",
    "                    X.append(features)\n",
    "                    y.extend([gesture_label] * features.shape[0])\n",
    "    X = np.vstack(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Step 6: Load and Preprocess Data\n",
    "# Load the dataset and preprocess it.\n",
    "# ```python\n",
    "X, y = load_data_from_directory(data_dir)\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape for 1D CNN\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7: Convert Labels to Integer Encoding\n",
    "# Encode the labels as integers.\n",
    "# ```python\n",
    "label_set = np.unique(y)\n",
    "label_map = {label: idx for idx, label in enumerate(label_set)}\n",
    "y_train_encoded = np.array([label_map[label] for label in y_train])\n",
    "y_test_encoded = np.array([label_map[label] for label in y_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 8: Define the 1D CNN Model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(len(label_set), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Save the architecture diagram\n",
    "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Step 9: Train the Model\n",
    "# Define early stopping and train the model.\n",
    "# ```python\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=30, batch_size=128,\n",
    "                    validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "# Save the trained model\n",
    "model.save('asl_gesture_model.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_encoded = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_encoded, axis=1)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test_encoded, y_pred, average=None, zero_division=0)\n",
    "\n",
    "# Print metrics for each letter\n",
    "for idx, label in enumerate(label_set):\n",
    "    print(f\"Letter: {label}\")\n",
    "    print(f\"  Precision: {precision[idx]:.4f}\")\n",
    "    print(f\"  Recall: {recall[idx]:.4f}\")\n",
    "    print(f\"  F1 Score: {f1[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 11: Plot Training History\n",
    "# Visualize the training and validation accuracy and loss.\n",
    "# ```python\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix with unique labels\n",
    "cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "\n",
    "\n",
    "# Create the confusion matrix display\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_set)\n",
    "\n",
    "# Plot without displaying values, just colors\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "disp.plot(ax=ax, include_values=True, colorbar=True)  # Use include_values=False to hide values\n",
    "\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "\n",
    "# Plotting the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, fmt=\"d\", cmap=\"summer\", xticklabels=label_set, yticklabels=label_set, cbar=True)\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "# Save the trained model\n",
    "#model.save('asl_gesture_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import serial\n",
    "# import numpy as np\n",
    "# import time\n",
    "# import tkinter as tk\n",
    "# from tkinter import Label\n",
    "\n",
    "# # Load the saved model\n",
    "# model = tf.keras.models.load_model('asl_gesture_model.h5')\n",
    "\n",
    "# # Initialize serial connection (adjust COM port and baud rate as per your device)\n",
    "# ser = serial.Serial('COM7', 115200, timeout=1)\n",
    "\n",
    "# # Create a dictionary to map gesture index to label\n",
    "# #label_set = ['A', 'B', 'C', 'D', 'E']  # Update this with your actual gesture labels\n",
    "\n",
    "# def get_real_time_data():\n",
    "#     if ser.in_waiting > 0:\n",
    "#         try:\n",
    "#             # Assuming the incoming data is comma-separated for flex sensors and quaternion values\n",
    "#             data = ser.readline().decode('utf-8').strip().split(',')\n",
    "#             data = np.array(data, dtype=float)  # Convert to float\n",
    "#             return data.reshape(1, -1, 1)  # Reshape to fit model input (1, num_features, 1)\n",
    "#         except:\n",
    "#             return None\n",
    "#     return None\n",
    "\n",
    "# # Function to perform gesture prediction\n",
    "# def predict_gesture():\n",
    "#     start_time = time.time()\n",
    "#     while time.time() - start_time < 15:  # 15 seconds to perform the gesture\n",
    "#         sensor_data = get_real_time_data()\n",
    "#         if sensor_data is not None:\n",
    "#             # Make prediction\n",
    "#             pred = model.predict(sensor_data)\n",
    "#             gesture_idx = np.argmax(pred, axis=1)  # Get the index of the highest probability\n",
    "#             predicted_gesture = label_set[gesture_idx[0]]  # Map to gesture label\n",
    "#             result_label.config(text=f\"Predicted Gesture: {predicted_gesture}\")\n",
    "#             root.update()\n",
    "#             time.sleep(0.1)  # Small delay to avoid too frequent polling\n",
    "#     buffer_time()  # Start the buffer after prediction\n",
    "\n",
    "# # Function to wait 15 seconds as a buffer before next prediction\n",
    "# def buffer_time():\n",
    "#     result_label.config(text=\"Buffer time... Wait for the next gesture.\")\n",
    "#     root.update()\n",
    "#     time.sleep(15)  # 15 seconds buffer\n",
    "#     predict_gesture()  # Start prediction again after buffer\n",
    "\n",
    "# # GUI Setup\n",
    "# root = tk.Tk()\n",
    "# root.title(\"ASL Gesture Recognition\")\n",
    "# root.geometry(\"400x200\")\n",
    "\n",
    "# # Label to display results\n",
    "# result_label = Label(root, text=\"Perform a gesture now...\", font=(\"Helvetica\", 16))\n",
    "# result_label.pack(pady=20)\n",
    "\n",
    "# # Start prediction immediately when the GUI opens\n",
    "# predict_gesture()\n",
    "\n",
    "# root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "with open('asl_gesture_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
